# PyTorch Practice

PyTorch: Empowering innovation in AI with intuitive and powerful tools for deep learning.

## Table of Contents

- [Overview](#overview)
- [Purpose](#purpose)
- [Introduction](#introduction)
- [Files](#files)
    - [Data Preprocessing](#data-preprocessing)
    - [Data Manipulation](#data-manipulation)
    - [Linear Algebra](#linear-algebra)
    - [Calculus](#calculus)
    - [Automatic Differentiation](#automatic-differentiation)
    - [Probability and Statistics](#probability-and-statistics)
- [Getting Started](#getting-started)
- [References](#references)

## Overview

This repository provides hands-on practice exercises and examples for **PyTorch**, covering a range of topics such
as `data preprocessing`, `data manipulation`, `linear algebra`, and more.

## Purpose

It aims to practice the basics of using **PyTorch** for machine learning and deep learning.

## Introduction

Each section of this repository is dedicated to a specific aspect of PyTorch. The exercises are contained in Jupyter
notebooks, allowing for interactive learning and experimentation. Topics include data preprocessing, linear algebra
operations, optimization techniques.

## Files

### Data Preprocessing

This notebook covers techniques for preparing raw data for machine learning models. It includes methods for handling
missing data, normalizing and standardizing features, and encoding categorical variables. These preprocessing steps are
essential for ensuring data quality and improving model performance.

### Data Manipulation

This notebook focuses on various data manipulation techniques using PyTorch. It includes operations such as slicing,
indexing, and transforming data tensors. You'll learn how to efficiently handle and manipulate data to prepare it for
training and analysis.

### Linear Algebra

This notebook introduces the fundamental concepts of linear algebra as they apply to machine learning. It covers
operations with vectors and matrices, matrix decomposition, and solving systems of linear equations using PyTorch.
Understanding these concepts is crucial for developing and optimizing machine learning algorithms.

### Calculus

This notebook explores the calculus concepts necessary for understanding and implementing machine learning algorithms.
It includes topics such as differentiation, integration, and partial derivatives. You'll learn how these concepts are
used in optimization and model training processes.

### Automatic Differentiation

This notebook delves into PyTorch's automatic differentiation feature, which is a core component of its deep learning
capabilities. learning how to use the `autograd` module to compute gradients automatically, which is essential for
backpropagation and optimization in neural networks.

### Probability and Statistics

This notebook covers the basics of probability and statistics with a focus on their applications in machine learning.
Topics include probability distributions, statistical tests, and descriptive statistics. These concepts are fundamental
for understanding data distributions and making inferences from data.

## Getting Started

1. Clone this repository to your local machine:

```zsh
git clone git@github.com:IsmaelMousa/playing-with-torch.git
```

2. Navigate to the **playing-with-torch** directory:

```zsh
cd playing-with-torch
```

3. Setup virtual environment:

```zsh
python3 -m venv .venv
```

4. Activate the virtual environment:

```zsh
source .venv/bin/activate
```

5. Install the required dependencies:

```zsh
pip install -r requirements.txt
```

### References

For more information on PyTorch, please refer to the official PyTorch
documentation: [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)